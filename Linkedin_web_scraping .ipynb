{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0054e77f-e8d0-4f9f-91e9-ec03dc81b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.4)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2023.7.22)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7dbd0de-3d06-4903-aee1-2b914f6ce140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import math\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a6c911-0181-47ce-845c-12fdb2e99f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b597b694-cfc1-4483-ba51-7af1824daa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "email=\"Your email\"\n",
    "password=\"your password\"\n",
    "jobss=\"Data Scientist\"\n",
    "loc=\"India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dab85d-cc87-46b3-ac18-d21e72337ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Driver path\n",
    "driver = webdriver.Chrome()  \n",
    "\n",
    "# Maximize Window\n",
    "driver.maximize_window() \n",
    "driver.minimize_window()  \n",
    "driver.maximize_window()  \n",
    "driver.switch_to.window(driver.current_window_handle)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# Enter to the site\n",
    "driver.get('https://www.linkedin.com/login');\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "driver.find_element(By.CSS_SELECTOR,\"input[name='session_key']\").send_keys(email)\n",
    "driver.find_element(By.CSS_SELECTOR,\"input[name='session_password']\").send_keys(password)\n",
    "driver.find_element(By.XPATH, '//button[@type=\"submit\"]').click()\n",
    "\n",
    "#====================================going to the Jobs page==================================================#\n",
    "driver.get('https://www.linkedin.com/jobs/search')\n",
    "## waiting load\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element(By.XPATH, '//*[@id=\"jobs-search-box-keyword-id-ember99\"]').send_keys(jobss)\n",
    "driver.find_element(By.XPATH,'//*[@id=\"jobs-search-box-location-id-ember99\"]').clear()\n",
    "driver.find_element(By.XPATH,'//*[@id=\"jobs-search-box-location-id-ember99\"]').send_keys(loc)\n",
    "driver.find_element(By.XPATH,'//*[@id=\"global-nav-search\"]/div/div[2]/button[1]').click()\n",
    "time.sleep(10)\n",
    "\n",
    "\n",
    "driver.find_element(By.XPATH,'//*[@id=\"searchFilter_timePostedRange\"]').click()\n",
    "time.sleep(10)\n",
    "driver.find_element(By.XPATH,\"//span[text()='Past week']\").click()\n",
    "driver.find_element(By.XPATH,\"//button[contains(@aria-label, 'Apply current filter to show') and contains(@aria-label, 'results') and contains(@class, 'artdeco-button--primary')]\").click()\n",
    "time.sleep(10)\n",
    "\n",
    "total_results_job=driver.find_element(By.XPATH,'//*[@id=\"main\"]/div/div[2]/div[1]/header/div[1]/small/div').text\n",
    "print(total_results_job)\n",
    "total_results= int(\"\".join(re.findall(r'\\d+', total_results_job)))\n",
    "\n",
    "total_pages = math.ceil(int(total_results)/25)\n",
    "print(total_pages) \n",
    "\n",
    "#========================going to the Jobs page==================================================#\n",
    "def collect_links(driver,3):#giving driver and total pages\n",
    "\n",
    "    links = []\n",
    "\n",
    "    try: \n",
    "        \n",
    "        #========================going to the Jobs page==================================================#\n",
    "        for page in range(2,total_pages+1):\n",
    "            time.sleep(2)\n",
    "            #==========================identify and get entire jobs links block=================#\n",
    "            jobs_block = driver.find_element(By.CLASS_NAME,'jobs-search-results-list')\n",
    "            \n",
    "            #============================get all job linkselements==============================#\n",
    "            jobs_list= jobs_block.find_elements(By.CLASS_NAME, 'job-card-list__entity-lockup')\n",
    "            \n",
    "            for i in jobs_list:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", i)\n",
    "                time.sleep(2)\n",
    "            #print(jobs_list)  \n",
    "                jobs_block = driver.find_element(By.CLASS_NAME,'jobs-search-results-list')\n",
    "                jobs_list= jobs_block.find_elements(By.CLASS_NAME, 'job-card-list__entity-lockup')\n",
    "            \n",
    "            #==========================identify and get entire jobs links block=================#\n",
    "            #============================get all job linkselements==============================#\n",
    "            jobs_block = driver.find_element(By.CLASS_NAME,'jobs-search-results-list')\n",
    "            jobs_list= jobs_block.find_elements(By.CLASS_NAME, 'job-card-list__entity-lockup')\n",
    "            \n",
    "            #print(jobs_block.find_elements(By.XPATH,all_links_xpath))\n",
    "            #=====================collect the links one by one===================================#\n",
    "            for job in jobs_list:\n",
    "                all_links = job.find_elements(By.TAG_NAME,'a')\n",
    "                #print(all_links)\n",
    "                for a in all_links:\n",
    "                    if str(a.get_attribute('href')).startswith(\"https://www.linkedin.com/jobs/view\") and a.get_attribute('href') not in links: \n",
    "                        links.append(a.get_attribute('href'))\n",
    "                    else:\n",
    "                        pass\n",
    "                # scroll down for each job element\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", job)\n",
    "                driver.implicitly_wait(10)\n",
    "            \n",
    "            #==========================going to the next page and prining the current time=============#\n",
    "            curr_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "            print(f'Collecting the links in the page: {page-1}',\"Current Time is :\", curr_time)\n",
    "            \n",
    "            #==========================going to 8th page and giving refresh=============================#\n",
    "            if page==8:\n",
    "                driver.refresh()\n",
    "                time.sleep(20)\n",
    "            #===================find the next page element and click to next page=======================#\n",
    "            driver.find_element(By.XPATH,f\"//button[@aria-label='Page {page}']\").click()\n",
    "            time.sleep(3)\n",
    "            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    driver.close()\n",
    "    \n",
    "    return links\n",
    "\n",
    "\n",
    "links = collect_links(driver,total_pages)\n",
    "\n",
    "\n",
    "\n",
    "'''jobs_block = driver.find_element(By.CLASS_NAME,'jobs-search-results-list')\n",
    "jobs_list= jobs_block.find_elements(By.CLASS_NAME, 'job-card-list__entity-lockup')\n",
    "for i in jobs_list:\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", i)\n",
    "                time.sleep(2)\n",
    "            #print(jobs_list)  \n",
    "                jobs_block = driver.find_element(By.CLASS_NAME,'jobs-search-results-list')\n",
    "                jobs_list= jobs_block.find_elements(By.CLASS_NAME, 'job-card-list__entity-lockup')\n",
    "\n",
    "jobs_block = driver.find_element(By.CLASS_NAME,'jobs-search-results-list')\n",
    "jobs_list= jobs_block.find_elements(By.CLASS_NAME, 'job-card-list__entity-lockup')\n",
    "links=[]\n",
    "for job in jobs_list:\n",
    "                all_links = job.find_elements(By.TAG_NAME,'a')\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", job)\n",
    "                driver.implicitly_wait(10)\n",
    "                for a in all_links:\n",
    "                        links.append(a.get_attribute('href'))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf17d3cc-7c5c-4e02-a46c-1548c9d30846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "df=pd.DataFrame({'Links':links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "805bdd59-b06e-4970-bf95-a37931b2296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title: Data Scientist\n",
      "Company Name: Synechron\n",
      "Location: Bengaluru, Karnataka, India\n",
      "Contact ID: https://in.linkedin.com/in/yekata-shriwas-b479a481?trk=public_jobs\n",
      "Company Link: https://www.linkedin.com/company/synechron?trk=public_jobs_topcard-org-name\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Define the LinkedIn job page URL\n",
    "url = \"https://www.linkedin.com/jobs/view/3932913303/?eBP=CwEAAAGP42Y6c723qOvmP09UAfYF6uDMAA_83mJuwFHaRR7kfGKTI-0sEH18Mo8N14UEHhygxkovgs9DoiPpUKvbZF-4Ct3e-MO5rX1fwXZ76-OAGjGYhC7BEL7ZS9SjgBHrv7nBWBhB2a6M8ltFPIL8oHm2WMFgLaxXWs3HnT59W-NKRHZlUN14K6xpZ38tFZVTVboXK-vUM_eTmGPuc6Fd-6QwhGwwK3eWFQoShY5lXHDSHxaeTOvcA3MHNUrhncTorhV7-LJIeX6kBti_Fh07eYVyIPeRUmux5_RZiGFKKyAwvqVuMj2lGuGmtB0d7J2sq8VPqekp0y7NxiH7AfE8T9Qop4OEsCWwcWTeMCzFA-fMihhjiM-JWW4yh_b13geg8DQKTXKW58x787EI0nbW4icUHuIqIaWKmPMM85zaR-i4Urck1Sh5dzJPw3YPCSiVUUQ3v6S2TBpo07lKMJoyRUK8Y2FW6J8&refId=FsSs28Bb7zZFzlhBMXRuHQ%3D%3D&trackingId=Ivt5d72OfbFyO7e%2BmYn4qg%3D%3D&trk=flagship3_search_srp_jobs\"\n",
    "\n",
    "# Load the page\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load completely\n",
    "\n",
    "# Get the HTML content\n",
    "html = driver.page_source\n",
    "# Close the WebDriver\n",
    "\n",
    "\n",
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "time.sleep(5)\n",
    "driver.quit()\n",
    "# Extract job details\n",
    "job_title = soup.find('h1', class_='top-card-layout__title').text.strip() if soup.find('h1', class_='top-card-layout__title') else 'Not Available'\n",
    "company_name = soup.find('a', class_='topcard__org-name-link').text.strip() if soup.find('a', class_='topcard__org-name-link') else 'Not Available'\n",
    "location = soup.find('span', class_='topcard__flavor topcard__flavor--bullet').text.strip() if soup.find('span', class_='topcard__flavor topcard__flavor--bullet') else 'Not Available'\n",
    "\n",
    "# Extract contact_id and company_link\n",
    "contact_id = soup.find('a', class_='base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]')['href'] if soup.find('a', class_='base-card__full-link absolute top-0 right-0 bottom-0 left-0 p-0 z-[2]') else 'Not Available'\n",
    "company_link = soup.find('a', class_='topcard__org-name-link')['href'] if soup.find('a', class_='topcard__org-name-link') else 'Not Available'\n",
    "\n",
    "# Print the extracted information\n",
    "print(\"Job Title:\", job_title)\n",
    "print(\"Company Name:\", company_name)\n",
    "print(\"Location:\", location)\n",
    "print(\"Contact ID:\", contact_id)\n",
    "print(\"Company Link:\", company_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75077771-7949-4a14-9aa3-8ea42dd56119",
   "metadata": {},
   "source": [
    "**Using for loop you can pass each link and fetch data and store in list and save as csv file** \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcc1f7-1387-4c8a-b78a-4257ae3bafcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
